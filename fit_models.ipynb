{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Evaluate Models\n",
    "\n",
    "Pre-Processing\n",
    "*   SMOTE\n",
    "*   Normalize\n",
    "\n",
    "Models\n",
    "* Logistic Regression\n",
    "* Linear SVC\n",
    "* KNeighborhs \n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_s = pd.read_csv(\"clean_data/features_s.csv\").iloc[:,1:]\n",
    "features_m = pd.read_csv(\"clean_data/features_m.csv\").iloc[:,1:]\n",
    "features = pd.read_csv(\"clean_data/features.csv\").iloc[:,1:]\n",
    "outcomes = pd.read_csv(\"clean_data/outcomes.csv\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "\n",
    "def smote_col(col, feats):\n",
    "  '''\n",
    "  SMOTE (balance binary classes)\n",
    "  for an outcome column in df\n",
    "  based on inputted features df\n",
    "  '''\n",
    "  x_smote, y_smote = smote.fit_resample(feats.astype(float), outcomes[col])\n",
    "  \n",
    "  x_smote = pd.DataFrame(x_smote)\n",
    "  x_smote.columns = feats.columns\n",
    "\n",
    "  y_smote = pd.DataFrame(y_smote)\n",
    "  y_smote.columns = [col]\n",
    "\n",
    "  return x_smote, y_smote\n",
    "\n",
    "#smote each feature set\n",
    "feature_sets = {\"features\": features, \n",
    "                \"features_m\": features_m,\n",
    "                \"features_s\": features_s}\n",
    "\n",
    "smotes = {}\n",
    "for time in [\"1Y\", \"5Y\"]:\n",
    "  for measure in [\"Median\", \"75th\"]: \n",
    "    for feat_set, features in feature_sets.items() :\n",
    "      var = \"Gentrified \" + time + \" \" + measure\n",
    "      x, y = smote_col(var, features)\n",
    "      smotes[var] = smotes.get(var, {}) \n",
    "      smotes[var][feat_set] = {\"X\": x, \"y\": y}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Grid Search --- # \n",
    "def grid_search(X_train, X_test, y_train, y_test, models, parameters, time, measure, feat_set):\n",
    "    \"\"\"\n",
    "    Looks for the best model based off a list of models and their parameters\n",
    "    \"\"\"    \n",
    "    # Begin timer \n",
    "    start = datetime.datetime.now()\n",
    "\n",
    "    # Initialize results data frame \n",
    "    results = []\n",
    "\n",
    "    # Loop over models \n",
    "    for model_key in models.keys(): \n",
    "\n",
    "        # Loop over parameters \n",
    "        for params in parameters[model_key]: \n",
    "            print(\"Training model:\", model_key, \"|\", params)\n",
    "            \n",
    "            # Create model \n",
    "            model = models[model_key]\n",
    "            model.set_params(**params)\n",
    "            #print(\"Model:\", model)\n",
    "            \n",
    "            # Normalize Features\n",
    "            new_model = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
    "\n",
    "            # Fit model on training set \n",
    "            new_model.fit(X_train, y_train.values.ravel())\n",
    "            \n",
    "            # Predict on testing set \n",
    "            y_hat = new_model.predict(X_test)\n",
    "            \n",
    "            # Evaluate predictions \n",
    "            mse_acc = metrics.accuracy_score(y_test, y_hat)\n",
    "            mse_prec = metrics.precision_score(y_test, y_hat)\n",
    "            mse_recall = metrics.recall_score(y_test, y_hat)\n",
    "            mse_f1 = metrics.f1_score(y_test, y_hat)\n",
    "            \n",
    "            # Store results in your results data frame \n",
    "            result = [time, measure, feat_set, model_key,params,mse_acc,mse_prec,mse_recall,mse_f1]\n",
    "            #print(result)\n",
    "            results.append(result)\n",
    "            \n",
    "    # End timer\n",
    "    stop = datetime.datetime.now()\n",
    "    print(\"Time Elapsed:\", stop - start) \n",
    "    return results\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LinearSVC | {'C': 0.01, 'random_state': 0, 'dual': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearSVC | {'C': 0.1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 10, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 100, 'random_state': 0, 'dual': False}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Time Elapsed: 0:02:46.568992\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LinearSVC | {'C': 0.01, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 0.1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 1, 'random_state': 0, 'dual': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearSVC | {'C': 10, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 100, 'random_state': 0, 'dual': False}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Time Elapsed: 0:02:33.465938\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LinearSVC | {'C': 0.01, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 0.1, 'random_state': 0, 'dual': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearSVC | {'C': 1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 10, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 100, 'random_state': 0, 'dual': False}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Time Elapsed: 0:02:45.647907\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LinearSVC | {'C': 0.01, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 0.1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 10, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 100, 'random_state': 0, 'dual': False}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Time Elapsed: 0:02:52.998240\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LinearSVC | {'C': 0.01, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 0.1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 10, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 100, 'random_state': 0, 'dual': False}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Time Elapsed: 0:03:06.420995\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'l2', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.01, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 0.1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 1, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 10, 'random_state': 0, 'max_iter': 5000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/carolinekinnen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: LogisticRegression | {'penalty': 'none', 'C': 100, 'random_state': 0, 'max_iter': 5000}\n",
      "Training model: LinearSVC | {'C': 0.01, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 0.1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 1, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 10, 'random_state': 0, 'dual': False}\n",
      "Training model: LinearSVC | {'C': 100, 'random_state': 0, 'dual': False}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 3, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 5, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 11, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'euclidean'}\n",
      "Training model: KNeighbors | {'n_neighbors': 19, 'weights': 'distance', 'metric': 'manhattan'}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "Training model: DecisionTree | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 5000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 5000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "Training model: RandomForest | {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 5000}\n",
      "Time Elapsed: 0:02:54.357156\n"
     ]
    }
   ],
   "source": [
    "# Config: Dictionaries of models and hyperparameters\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(), \n",
    "    'LinearSVC': LinearSVC(), \n",
    "    'KNeighbors': KNeighborsClassifier(), \n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "grid = {\n",
    "    'LogisticRegression': [{'penalty': x, 'C': y, 'random_state': 0, 'max_iter': 5000} \n",
    "                           for x in ('l2', 'none') \\\n",
    "                           for y in (0.01, 0.1, 1, 10, 100)],\n",
    "    'LinearSVC': [{'C': x, 'random_state': 0, 'dual': False} \\\n",
    "                  for x in (0.01, 0.1, 1, 10, 100)],\n",
    "    'KNeighbors': [{'n_neighbors':x, \"weights\":y, \"metric\":z} \\\n",
    "                   for x in (3,5,11,19) \\\n",
    "                   for y in ('uniform','distance') \\\n",
    "                   for z in ('euclidean','manhattan')], \n",
    "    'DecisionTree': [{'criterion':x, \"max_depth\":y, \"min_samples_split\":z} \\\n",
    "                   for x in ('gini', 'entropy') \\\n",
    "                   for y in (1,3,5) \\\n",
    "                   for z in (2,5,10)],\n",
    "    'RandomForest': [{'criterion':x, \"max_depth\":y, \"min_samples_split\":z, \"n_estimators\":a} \\\n",
    "                   for x in ('gini', 'entropy') \\\n",
    "                   for y in (1,3,5) \\\n",
    "                   for z in (2,5,10) \\\n",
    "                   for a in (100,1000,5000)]\n",
    "}\n",
    "\n",
    "full_results = pd.DataFrame(columns=['Outcome Timeframe', \n",
    "                                     'Outcome Benchmark',\n",
    "                                     'Feature Set',\n",
    "                                     'Model',\n",
    "                                     'Parameters', \n",
    "                                     'Accuracy',\n",
    "                                     'Precision',\n",
    "                                     'Recall',\n",
    "                                     'F1 Score'])\n",
    "\n",
    "#run grid search on each outcome and feature set\n",
    "for time in [\"1Y\", \"5Y\"]:\n",
    "    for feat_set, features in feature_sets.items() :\n",
    "      var = \"Gentrified \" + time + \" Median\"\n",
    "      X_train, X_test, y_train, y_test = train_test_split(smotes[var][feat_set][\"X\"], \n",
    "                                                          smotes[var][feat_set][\"y\"], \n",
    "                                                          test_size=0.2,\n",
    "                                                          random_state=0)\n",
    "      results = grid_search(X_train, X_test, y_train, y_test, \n",
    "                            models, grid, time, \"Median\", feat_set)\n",
    "      results_df = pd.DataFrame(results, columns=['Outcome Timeframe', \n",
    "                                    'Outcome Benchmark',\n",
    "                                    'Feature Set',\n",
    "                                    'Model',\n",
    "                                    'Parameters', \n",
    "                                    'Accuracy',\n",
    "                                    'Precision',\n",
    "                                    'Recall',\n",
    "                                    'F1 Score'])\n",
    "      full_results = full_results.append(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Best Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-1091e96c3d42>:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  best_model.fit(X_train, y_train)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_jobs=-1, random_state=0,\n",
       "                       verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1Y Median\n",
    "sorted = full_results[(full_results[\"Outcome Timeframe\"] == \"1Y\") & \n",
    "             (full_results[\"Outcome Benchmark\"] == \"Median\")].sort_values([\"Accuracy\", \"Precision\"])\n",
    "#dic = dict(sorted[-1:][\"Parameters\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(smotes[\"Gentrified 1Y Median\"][\"features_s\"][\"X\"],\n",
    "                                                    smotes[\"Gentrified 1Y Median\"][\"features_s\"][\"y\"],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "best_model = RandomForestClassifier(n_estimators=100, \n",
    "                               random_state=0, \n",
    "                               min_samples_split=5,\n",
    "                               n_jobs=-1, \n",
    "                               verbose = 1)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_\n",
    "index = np.arange(len(importances))\n",
    "fi = plt.figure(figsize=(8,6))\n",
    "fi = plt.bar(X_train.columns.values, importances)\n",
    "fi = plt.xlabel('Features')\n",
    "fi = plt.ylabel('Importance')\n",
    "fi = plt.xticks(rotation=45, horizontalalignment='right')\n",
    "fi = plt.title('Importance of Each Feature from Random Forest')\n",
    "plt.show(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5Y Median\n",
    "full_results[(full_results[\"Outcome Timeframe\"] == \"5Y\") & \n",
    "             (full_results[\"Outcome Benchmark\"] == \"Median\")].sort_values(\"Accuracy\")\n",
    "\n",
    "#largest feature sets perform best. Decision Tree does surprisingly well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
